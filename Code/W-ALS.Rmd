---
title: "Weighted Alternating Least Squares with the LastFM Dataset"
author: "William Morgan"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: pdf_document
---

```{r setup, include=FALSE}
rm(list = ls(all = TRUE))
libs <-  c("data.table", "tidyverse", "Matrix", "rsparse", "parallel", "stringr")
suppressPackageStartupMessages(lapply(libs, library, character.only = T))
```

## Load data

```{r Load and add names, cache = TRUE}
# Load data and add names
raw_data <-  fread("Data/lastfm-dataset-360K/usersha1-artmbid-artname-plays.tsv", showProgress = F) 

names(raw_data) <- c("user_id", "artist_id", "artist_name", "number_plays")

raw_data <- raw_data %>%
  filter(str_length(artist_id) > 10)

```
*** 

## Tidy data

```{r Tidy data}
# Use integer-valued ids for users and items
user_encoding <-  raw_data %>%
  distinct(user_id) %>%
  mutate(uid = row_number())
  
item_encoding <- raw_data %>%
  distinct(artist_id, artist_name) %>%
  mutate(iid = row_number())

data <-  raw_data %>%
  inner_join(user_encoding, by = 'user_id') %>%
  inner_join(item_encoding, by = 'artist_id')

rm(raw_data)
```

*** 

## Split data
- We use 30K listeners in our test set
- For each listener in the testing set, we need to randomly split their listens 
into history and future listens (this is done for testing)

```{r train/test split}
# Define our model matrix
X = sparseMatrix(i = data$uid, j = data$iid, x = data$number_plays, 
                 dimnames = list(user_encoding$user_id, item_encoding$artist_name))

n_test <- 30000L
test_uid <- sample(nrow(user_encoding), n_test)

X_train <-  X[-test_uid, ]
X_test <-  X[test_uid, ]

# Split our test set into "history" or "future"
temp = as(X_test, "TsparseMatrix")
temp = data.table(i = temp@i, j = temp@j, x = temp@x) 

temp <- temp %>%
  group_by(i) %>%                         # group by user
  mutate(ct = length(j),                  # number of artists each user has
         history = 
           sample(c(TRUE, FALSE), ct, replace = TRUE, prob = c(.5, .5))) %>%
  select(-ct)

X_test_history <- temp %>% filter(history == TRUE)
X_test_future <- temp %>% filter(history == FALSE)

rm(temp)

# Convert them back to sparse matrices
X_test_history <- sparseMatrix(i = X_test_history$i,
                               j = X_test_history$j,
                               x = X_test_history$x,
                               dims = dim(X_test),
                               dimnames = dimnames(X_test),
                               index1 = FALSE)

X_test_future <- sparseMatrix(i = X_test_future$i,
                              j = X_test_future$j,
                              x = X_test_future$x,
                              dims = dim(X_test),
                              dimnames = dimnames(X_test),
                              index1 = FALSE)

rm(user_encoding, item_encoding, n_test, test_uid, data)
```
*** 

## Confidence Measures
Recall our loss function:

$$
L = \sum_u\sum_ic_{ui}(p_{ui} - x^{T}_uy_i)^2 + \lambda(\Vert{X}\Vert^2 + \Vert{Y}\Vert^2)
$$
We need to define two functions that will allow us to create the confidence matrix:
$$
\begin{aligned}
c_{ui} = 1 + \alpha log(1 + \frac{r_{ui}}{\epsilon}) \\
c_{ui} = 1 + \alpha log(1 + r_{ui})
\end{aligned}
$$
$\alpha$ and $\epsilon$ are hyperparameters that should be tuned using CV

```{r conf func}
# Define confidence functions and create matrices
log_conf <-  function(x, alpha, epsilon){
  x_confidence <-  x
  stopifnot(inherits(x, "sparseMatrix"))
  x_confidence@x = 1 + alpha * log(1 + (x@x / epsilon))
  return(x_confidence)
}

lin_conf <- function(x, alpha) {
  x_confidence <- x
  stopifnot(inherits(x, "sparseMatrix"))
  x_confidence@x = 1 + alpha * x@x
  return(x_confidence)
}


```


## Practice Model

```{r model setup}
# Define hyperparameters
alpha <- .1
lambda <- 10
components <- 10L

# Create Confidence Matrices
X_train_conf <- lin_conf(X_train, alpha)
X_test_history_conf <- lin_conf(X_test_history, alpha)

# Initialize a model
model <- WRMF$new(rank = components,
                  lambda = lambda,
                  feedback = 'implicit',
                  solver = 'conjugate_gradient')

# Add scoring metrics
model$add_scorers(x_train = X_test_history_conf, x_cv = X_test_future,
                  list("map10" = "map@10", "ndcg-10" = "ndcg@10"))

# Calculate user factors
train_user_factors <- model$fit_transform(X_train_conf)

# Make ALS step given fixed items matrix, and then predict for those users top K items
test_predictions <- model$predict(X_test_history_conf, k = 10)

trace = attr(train_user_factors, "trace")
ggplot(trace) +
  geom_line(aes(x = iter, y = value, col = scorer)) +
  labs(title = "Loss and Scoring Metrics by iteration") +
  theme(plot.title = element_text(hjust = .5))

```


## Tune Model - Linear Confidence

```{r tuning model, eval = F}
# Convergence parameters
n_iter_max = 10L
convergence_tol = .01

# Hyperparameters to test
grid = expand.grid(alpha = c(.01, 1),
                   rank = c(16, 64, 128),
                   lambda = c(100))

# Empty vector to throw results into
lin_scores <-  vector("list", nrow(grid))

for (k in seq_len(nrow(grid))){
  # Define parameters
  alpha = grid$alpha[[k]]
  rank = grid$rank[[k]]
  lambda = grid$lambda[[k]]

  # Initialize
  model <- WRMF$new(rank = rank,
                    lambda = lambda,
                    feedback = 'implicit',
                    solver = 'conjugate_gradient')
  
  # Conf. matrices
  X_train_conf<- lin_conf(X_train, alpha)
  X_test_history_conf <- lin_conf(X_test_history, alpha)

  
  # Scoring metrics
  model$add_scorers(x_train = X_test_history_conf,
                    x_cv = X_test_future,
                    list("map10" = "map@10", "ndcg-10" = "ndcg@10"))
  
  # Fit
  fit <-  model$fit_transform(X_train_conf, n_iter = n_iter_max,
                              convergence_tol = convergence_tol)

  # Extract score
  score <-  attr(fit, "trace")
  
  score$alpha = alpha
  score$lambda = lambda
  score$rank = rank

  # Add to list
  lin_scores[[k]] <-  score
  
  # Clean up
  rm(alpha, rank, lambda, model, score)
}

lin_results <-  bind_rows(lin_scores) %>%
  group_by(alpha, lambda, rank, scorer) %>%
  arrange(iter) %>%
  filter(row_number() == n()) %>%
  select(-iter) %>%
  ungroup()

fwrite(lin_results, "Data/linear confidence results.csv")

```

```{r print results}
lin_results <- fread("Data/linear confidence results.csv")

print("Best Performing Models by MAP@10")
lin_results %>%
  filter(scorer == "map10") %>%
  arrange(desc(value))

print("Best Performing Models by NDCG@10")
lin_results %>%
  filter(scorer == "ndcg-10") %>%
  arrange(desc(value))
```



```{r log conf, eval = F}
# Convergence parameters
n_iter_max = 10L
convergence_tol = .01

# Hyperparameters to test
grid = expand.grid(alpha = c(.01, 1, 100),
                   rank = c(16, 64, 128),
                   lambda = c(.01, 1, 100),
                   epsilon = c(.01, 1, 100))

# Empty vector to throw results into
log_scores <-  vector("list", nrow(grid))

for (k in seq_len(nrow(grid))){
  # Define parameters
  alpha = grid$alpha[[k]]
  rank = grid$rank[[k]]
  lambda = grid$lambda[[k]]
  epsilon = grid$epsilon[[k]]

  
  # Initialize
  model <- WRMF$new(rank = rank,
                    lambda = lambda,
                    feedback = 'implicit',
                    solver = 'conjugate_gradient')
  
  # Conf. matrices
  X_train_conf <- log_conf(X_train, alpha, epsilon)
  X_test_history_conf <- log_conf(X_test_history, alpha, epsilon)

  # Scoring metrics
  model$add_scorers(x_train = X_test_history_conf,
                    x_cv = X_test_future,
                    list("map10" = "map@10", "ndcg-10" = "ndcg@10"))
  
  # Fit
  fit <-  model$fit_transform(X_train_conf, n_iter = n_iter_max,
                              convergence_tol = convergence_tol)

  # Extract score
  score <-  attr(fit, "trace")
  
  score$alpha = alpha
  score$lambda = lambda
  score$rank = rank
  score$epsilon = epsilon
  
  # Add to list
  scores[[k]] <-  score
  
  # Clean up
  rm(alpha, rank, lambda, model, score, epsilon)
}


```







